{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "instrument_recognition_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xjjSDBjiBLw8"
      ],
      "authorship_tag": "ABX9TyNZW+DMNWbQLxJ21JhEHsH1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrodenburg/instrument_recognition/blob/Jeroen/instrument_recognition_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3LxhezCBjHi",
        "colab_type": "text"
      },
      "source": [
        "# <font color = #003399> **Instrument recognition** </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABKt-lmXBZTf",
        "colab_type": "text"
      },
      "source": [
        "## <font color = \"purple\"> **Initialize** </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_nIC2yLr7_D",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Import packages** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MixP7uByFt0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os       # For path-manipulations etc\n",
        "\n",
        "import librosa  # For all kinds of audio manipulations\n",
        "from librosa import display\n",
        "\n",
        "from IPython.display import Audio #to play audio inside the notebook\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7pQyQazsDgL",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Mount google drive** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCqcpjkvUNEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7bfd9889-23af-4b26-8503-e7f1d8c0e812"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/3wFLI8Rjkn0A73wPGAgM7OuM7ozqVzeMoDAjmulNDI1KZBr6-SnGzAw\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjSDBjiBLw8",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"purple\"> **Import data** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofZpbKAue0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_data(data_dir, ins_annotations, max_songs_per_annotation = None):\n",
        "  \"\"\"\n",
        "  Imports the data.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data_dir : string\n",
        "    Path of the directory that contains the data. It is assumed that \n",
        "    this directory contains subdirectories, whose titles are given by\n",
        "    the annotations of the various instruments. The actual sound-files \n",
        "    are inside these subfolders.\n",
        "\n",
        "  ins_annotations : array of strings\n",
        "    List of the annotations of the various annotations - these strings \n",
        "    also the names of the subfolders that contain the data with that \n",
        "    annotation.\n",
        "\n",
        "  max_songs_per_annotations : int, optional\n",
        "    Maximum number of songs to include per annotation. Useful to test my code\n",
        "    while working only a smaller dataset.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  sampling_rates : np.array of ints\n",
        "    List of the sample-rates (in Hz) of all the music-files\n",
        "\n",
        "  data : list of np.arrays\n",
        "    List of time-domain data (in np.array format) of all music snippets.\n",
        "\n",
        "  classifications : np.array of strings\n",
        "    List of the annotation for every song - the annotation is for\n",
        "    the predominant instrument.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initalize the to-be-returned np.arrays\n",
        "  sampling_rates = [] #note: I'm choosing this to be a list, not a np.arrary.\n",
        "                    #The reaons is not very good -  but it seems easier to \n",
        "                    # append integers to a list. \n",
        "                    # If I were to intiialize sampling_rates as a np.array, \n",
        "                    # every entry of sampling_rates is automatically treated\n",
        "                    # as float64..\n",
        "  data = [] # note: its type is list, not np.array, because the data-signals \n",
        "            # it contains may - in principle - be of different length\n",
        "  classifications = np.array([])\n",
        "\n",
        "  # Import:\n",
        "  for annotation in ins_annotations:\n",
        "\n",
        "    print(f\"\\nImporting data with annotation '{annotation}'\")\n",
        "    data_subdir = os.path.join(data_dir,annotation)\n",
        "    list_filenames = os.listdir(data_subdir)\n",
        "\n",
        "    # Initialize counter that counts how many files are imported with this\n",
        "    # annotation --  used only to print this number during the importing.\n",
        "    counter = 0\n",
        "\n",
        "    for filename in list_filenames[:max_songs_per_annotation]:\n",
        "\n",
        "      dt, sr = librosa.load( os.path.join(data_subdir,filename), sr = None, mono = False )\n",
        "\n",
        "      data.append(dt)\n",
        "      sampling_rates.append( int(sr) )\n",
        "      classifications = np.append(classifications,annotation)\n",
        "\n",
        "      # print the number of imported snippets so far:\n",
        "      counter = counter + 1\n",
        "      print(f\"\\rImported snippets: {counter} of {len(list_filenames)}\", end = '')\n",
        "\n",
        "  return sampling_rates, data, classifications"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX_7JByJA5Eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "8d655098-a9d3-4b6e-8410-7946a382d441"
      },
      "source": [
        "# Set working directory for this project\n",
        "base_dir = '/content/drive/My Drive/Colab Notebooks/instrument_recognition'\n",
        "os.chdir(base_dir)\n",
        "\n",
        "# Data directory:\n",
        "data_dir = os.path.join(base_dir,'data','IRMAS','trainingdata')\n",
        "# List of the strings used as instrument annotations\n",
        "ins_annotations = ['cel','cla','flu','gac','gel','org','pia','sax','tru','vio','voi']\n",
        "\n",
        "#Import data\n",
        "sampling_rates, data, y = import_data(data_dir, ins_annotations, max_songs_per_annotation = None)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Importing data with annotation 'cel'\n",
            "Imported snippets: 388 of 388\n",
            "Importing data with annotation 'cla'\n",
            "Imported snippets: 505 of 505\n",
            "Importing data with annotation 'flu'\n",
            "Imported snippets: 451 of 451\n",
            "Importing data with annotation 'gac'\n",
            "Imported snippets: 637 of 637\n",
            "Importing data with annotation 'gel'\n",
            "Imported snippets: 760 of 760\n",
            "Importing data with annotation 'org'\n",
            "Imported snippets: 121 of 682"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ad752c89db00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msampling_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_songs_per_annotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-0024598e7a05>\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(data_dir, ins_annotations, max_songs_per_annotation)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_songs_per_annotation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m       \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Return to the beginning of the file to try the next reader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36minitfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soundpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'FORM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file does not start with FORM id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/chunk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mstrflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJnlhtlC9kI",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"purple\"> **Preprocessing** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlPBSFADYbHJ",
        "colab_type": "text"
      },
      "source": [
        "**Features**: The first *n_mfcc* mel-frequency cepstral coefficients, time-averaged over all time-windows. *n_mfcc* can be specified.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y_qlA0pV2nh",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Supporting functions** </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrf49MsWVWAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain_average_mfccs(data, sampling_rates, window_time, time_step = None, n_mfcc = 20):\n",
        "  \"\"\"\n",
        "  Obtains, for every time-profile in 'data', the MFCC's (averaged over all time-windows) \n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data : list of m np.arrays of shape 2 x something\n",
        "    Here m is the number of snippets. Every entry of data contains the time-series of a single music snippet, \n",
        "    which is assumed to be stereo.\n",
        "\n",
        "  sampling_rates : list of m ints\n",
        "    Every int is the sample rate of the corresponding entry in data.\n",
        "\n",
        "  window_time : float\n",
        "    Length in seconds of a window to be used in the short-time Fourier transform,\n",
        "    that is part of the mfcc-routine.\n",
        "\n",
        "  time_step : float, optional\n",
        "    Length in seconds of the time step between two successive windows.\n",
        "    If not provided, it is set to window_time/2.\n",
        "\n",
        "  n_mfcc : int\n",
        "    Number of to-be-returned mel-frequency cepstral coefficients per snippet.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  average_mfccs : np.array of shape m x 2 x n_mfcc\n",
        "    Every entry of this list corresponds to one entry of data, and contains \n",
        "    the mfcc's averaged of the left- and right-component of the stereo signal.\n",
        "  \"\"\"\n",
        "\n",
        "  # If time_step is not defined, give it a standard value:\n",
        "  if time_step == None:\n",
        "    time_step = window_time / 2\n",
        "    print(f'The time-step is not specifed and therefore set to the standard value: window_time/2 = {time_step}')\n",
        "\n",
        "  # Define useful variable:\n",
        "  m = len(data)\n",
        "\n",
        "  # Initialize the to-be-returned np.array of average mfccs\n",
        "  average_mfccs = np.zeros((m,2,n_mfcc))\n",
        "\n",
        "  # Loop over data samples (snippets), \n",
        "  # and calculate the average mfcc's for every sample\n",
        "  for i in range(m):\n",
        "    # Parameters for dividing total time sample into windows:\n",
        "    ## Length of a window\n",
        "    n_fft = int(np.ceil(sampling_rates[i]*window_time)) \n",
        "    ## Hop length between two successive windows\n",
        "    hop_length = int(np.ceil(sampling_rates[i]*time_step))\n",
        "\n",
        "    # Calculate the mffc for the left- and right-audio\n",
        "    mfccs_left = librosa.feature.mfcc(data[i][0], sr = sampling_rates[i], n_fft = n_fft, hop_length = hop_length)\n",
        "    mfccs_right = librosa.feature.mfcc(data[i][1], sr = sampling_rates[i], n_fft = n_fft, hop_length = hop_length)\n",
        "\n",
        "    # Average mfccs over all time-windows,\n",
        "    # and store result in average_mfccs:\n",
        "    average_mfccs[i,0] = np.mean(mfccs_left,axis=1)\n",
        "    average_mfccs[i,1] = np.mean(mfccs_right,axis=1)\n",
        "\n",
        "    print(f'\\rNumber of average mfccs obtained: {i+1} out of {m}', end = '')\n",
        "\n",
        "  return average_mfccs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHF__E6VgCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardize(X, axis = None):\n",
        "  \"\"\"\n",
        "  `Standardizes' the elements of a 2D array: \n",
        "  To every entry we substract the mean of its column\n",
        "  and divide by the standard-deviation of its column.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X : np.array of shape (m,n) for ints m, n\n",
        "    To-be-standardized array\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  X_std : np.array of shape (m,n)\n",
        "    Standardized array\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute mean and standarddeviation for every column:\n",
        "  mu = np.mean(X, axis = 0)\n",
        "  sigma = np.std(X, axis = 0)\n",
        "\n",
        "  # For every element of array: \n",
        "  # substract mean and divide by standarddeviation\n",
        "  X_std = (X - mu)/sigma\n",
        "  ## Note that the shapes of array, mu and sigma do not match,\n",
        "  ## but the broadcasting property of the python operations '-'\n",
        "  ## and '/' ensures that it works as it should.\n",
        "\n",
        "  return X_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljpFr9KtELkY",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Perform the preprocessing** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T7oixwc5JAm",
        "colab_type": "text"
      },
      "source": [
        "**Remark on splitting of the data**: I'm using the IRMAS 'trainingdataset' as my **entire** dataset - which I will split into training, cross-validation and testingsets. This is the simplest thing to do right now. They also provide 'trainingdata', but it's of a different format than their trainingdata (longer snippets etc). It's interesting to test a trained classifier on that too - but a bit more complicated. For now, let's do the simplest thing possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMQ5XNpqE0UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_using_mfccs(data, sampling_rates, y,\\\n",
        "                           window_time, time_step = None, n_mfcc = 20,\\\n",
        "                           fraction_train = 0.6, fraction_test = 0.2):\n",
        "  '''\n",
        "  Takes the time-data, its sampling rates and its labels, and performs \n",
        "  the preprocessing: it returns the data and labels ready to be used for\n",
        "  machine learning algorithms. As features it uses, for every snippet, its\n",
        "  n_mfcc first time-averaged mfccs. It also separates the data into training, \n",
        "  cross-validation, and testdata. And it standardizes the features, i.e.\n",
        "  it makes sure that distribution of every coefficient has zero mean and unit\n",
        "  variance.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data : list of m np.arrays of shape 2 x something\n",
        "    Here m is the number of snippets, and `something' the number of \n",
        "    time-samples of a single snippet. Every entry of data contains \n",
        "    the time-series of a single music snippet, which is assumed to be stereo.\n",
        "  \n",
        "  y : list of m strings.\n",
        "    y[i] is the annotation that corresponds to the snippet encoded by data[i].\n",
        "\n",
        "  sampling_rates : list of m ints\n",
        "    Every int is the sample rate of the corresponding entry in data.\n",
        "\n",
        "  window_time : float\n",
        "    Length in seconds of a window to be used in the short-time Fourier transform,\n",
        "    that is part of the mfcc-routine.\n",
        "\n",
        "  time_step : float, optional\n",
        "    Length in seconds of the time step between two successive windows.\n",
        "    If not provided, it is set to window_time/2.\n",
        "\n",
        "  n_mfcc : int, optional\n",
        "    Number of to-be-returned mel-frequency cepstral coefficients per snippet.\n",
        "    Standard value is 20.\n",
        "\n",
        "  fraction_train : float, s.t. 0 <= fraction_train <= 1.\n",
        "    Fraction of the total dataset to be used as trainingset.\n",
        "  \n",
        "  fraction_CV : float, s.t. 0 <= fraction_CV <= 1 - fraction_train.\n",
        "    Fraction of the total dataset to be used as trainingset.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train, n_mfcc)\n",
        "    Standardized training data. \n",
        "    Standardized means that every subset X_train[:,n_mfcc] was:\n",
        "      1. Shifted s.t. its mean = 0.\n",
        "      2. Normalized s.t. its standarddeviation = 1.\n",
        "  \n",
        "  X_CV_std : np.array of shape (m_CV, n_mfcc)\n",
        "    Standardized cross-validation data.\n",
        "\n",
        "  X_test_std : np.array of shape (m_test, n_mfcc)\n",
        "    Standardized testdata.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training data.\n",
        "\n",
        "  y_CV : np. array of shape (m_CV,)\n",
        "    Labels of cross-validation data.\n",
        "\n",
        "  y_test : np.array of shape (m_test,)\n",
        "    Labels of testdata.\n",
        "  '''\n",
        "\n",
        "  # Steps:\n",
        "  # (1) Obtain the time-averaged mfccs of every sample.\n",
        "  # (2) Reshape the resulting list of our stereo-data into more suitable format.\n",
        "  # (3) Split into training, cross-validation and testset.\n",
        "  # (4) Standardize features.\n",
        "\n",
        "  # Useful variable:\n",
        "  m = len(data)\n",
        "\n",
        "  # Step (1): Obtain the time-averaged mfccs of every sample.\n",
        "  average_mfccs = obtain_average_mfccs(data, sampling_rates, window_time = 0.030)\n",
        "\n",
        "  # Step (2): Reshape the resulting list of our stereo-data into more suitable format.\n",
        "  X = np.reshape(average_mfccs,(m,2*n_mfcc))\n",
        "\n",
        "  # Step (3): Split into training, cross-validation and testset.\n",
        "  ## Before splitting, we shuffle X & y:\n",
        "  from sklearn.utils import shuffle\n",
        "  X_shuffled, y_shuffled = shuffle(X,y)\n",
        "\n",
        "  ## Now, we split:\n",
        "\n",
        "  ### Define the fractions of the data to be used\n",
        "  ### for training, and cross-validation (CV); \n",
        "  ### the remainder will be the testing fraction:\n",
        "\n",
        "  fraction_train = 0.6\n",
        "  fraction_CV    = 0.2\n",
        "\n",
        "  ### Number of samples for training, CV and testing:\n",
        "  m_train = int( np.ceil( fraction_train * m ) )\n",
        "  m_CV    = int( np.ceil( fraction_CV * m  ) )\n",
        "  m_test  = m - m_train - m_CV\n",
        "\n",
        "  ### Split\n",
        "\n",
        "  X_train = X_shuffled[:m_train]\n",
        "  X_CV    = X_shuffled[m_train:(m_train+m_CV)]\n",
        "  X_test  = X_shuffled[-m_test:]\n",
        "\n",
        "  y_train = y_shuffled[:m_train]\n",
        "  y_CV    = y_shuffled[m_train:(m_train+m_CV)]\n",
        "  y_test  = y_shuffled[-m_test:]\n",
        "\n",
        "  # Step (4): Standarddize all features.\n",
        "\n",
        "  X_train_std = standardize(X_train)\n",
        "  X_CV_std = standardize(X_CV)\n",
        "  X_test_std = standardize(X_test)\n",
        "\n",
        "  return X_train_std, X_CV_std, X_test_std, y_train, y_CV, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puslXSr9M8lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d25171b-a02d-4fbc-c152-c695a6d06812"
      },
      "source": [
        "X_train_std, X_CV_std, X_test_std, y_train, y_CV, y_test = \\\n",
        "  preprocess_using_mfccs(data, sampling_rates, y,\\\n",
        "                         window_time = 0.030, time_step = None, n_mfcc = 20,\\\n",
        "                         fraction_train = 0.6, fraction_test = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time-step is not specifed and therefore set to the standard value window_time/2 = 0.015\n",
            "Number of average mfccs obtained: 6705 out of 6706"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9zgmgLCHB2",
        "colab_type": "text"
      },
      "source": [
        "## <font color = \"purple\"> **Machine-learning** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv_j3xDqP0Bx",
        "colab_type": "text"
      },
      "source": [
        "Let's try a few different classifiers with different algorithms, and compare them. Let's start as simple as possible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFHSe2OP-lY",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Simple logistic regression** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W4IdhZHRC37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1rQWuGhZGd3",
        "colab_type": "text"
      },
      "source": [
        "#### <font color = '#CC3300'> **Compare different regularization parameters** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r37Io2uzfABu",
        "colab_type": "text"
      },
      "source": [
        "##### <font color = 'blue'> **Supporting functions** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s0e5DpPyIVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_performance_LR(X_train_std, y_train, X_CV_std, y_CV, C):\n",
        "  '''\n",
        "  Trains a Logistic-Regression-Classifier on a trainingset, \n",
        "  and returns its accuracy on the trainingset, as well as on a separate set\n",
        "  (cross-validation or test-set)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train,n_train)\n",
        "    Training data of m_train training samples and n_train standardized features.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training set\n",
        "\n",
        "  X_CV_std : np.array of shape (m_CV,n_CV)\n",
        "    Cross-validation or testing data of m_CV training samples\n",
        "    and n_CV standardized features.\n",
        "\n",
        "  y_CV : np.array of shape (m_CV,)\n",
        "    Labels of cross-valdation or test set.\n",
        "\n",
        "  C : float64 \n",
        "    inverse regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  np.array([score_train,score_CV]), where:\n",
        "\n",
        "  score_train : float 64 (where 0 <= score_train <=1 )\n",
        "    Accuracy of the trained logistic-regression-model on the training set.\n",
        "\n",
        "  score_CV : float 64 (where 0 <= score_CV <=1 )\n",
        "    Accuracy of the trained logistic-regression-model \n",
        "    on the cross-validation/test set.\n",
        "  '''\n",
        "\n",
        "  # Initalize Logistic Regression model\n",
        "  logisticRegr = LogisticRegression(C = C, max_iter = 1000)\n",
        "\n",
        "  # Train it\n",
        "  logisticRegr.fit(X_train_std, y_train)\n",
        "\n",
        "  # Evaluate accuracies\n",
        "  score_train = logisticRegr.score(X_train_std, y_train)\n",
        "  score_CV    = logisticRegr.score(X_CV_std   , y_CV)\n",
        "\n",
        "  return np.array([score_train,score_CV])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FLTyiVMZX_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_regparams(X_train_std, y_train, X_CV_std, y_CV,\\\n",
        "                      C_list= np.array([0.001,0.003,0.01,0.03,0.1,0.3,\\\n",
        "                              1,3,10,30,100,300,1000])\\\n",
        "                      ):\n",
        "  '''\n",
        "  Evaluates the performance of the logistic regression classifier for several\n",
        "  (inverse) regularaization parameters 'C'. Selects the best one by finding \n",
        "  the maximum accuracy on the cross-validation set. Returns the scores for \n",
        "  every C, the optimal C, and the optimal classifier.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train,n_train)\n",
        "    Training data of m_train training samples and n_train standardized features.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training set\n",
        "\n",
        "  X_CV_std : np.array of shape (m_CV,n_CV)\n",
        "    Cross-validation or testing data of m_CV training samples\n",
        "    and n_CV standardized features.\n",
        "\n",
        "  y_CV : np.array of shape (m_CV,)\n",
        "    Labels of cross-valdation or test set.\n",
        "\n",
        "  C_list : np.array of float64's \n",
        "    inverse regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  np.array([score_train,score_CV]), where:\n",
        "\n",
        "    score_train : float 64 (where 0 <= score_train <=1 )\n",
        "      Accuracy of the trained logistic-regression-model on the training set.\n",
        "\n",
        "    score_CV : float 64 (where 0 <= score_CV <=1 )\n",
        "      Accuracy of the trained logistic-regression-model \n",
        "    on the cross-validation/test set.\n",
        "  \n",
        "  C_best : float64\n",
        "    Optimal value of C, meaning that value of 'C_list' for which the accuracy \n",
        "    on the cross-validation set is maximal.\n",
        "\n",
        "  LR_best : LogisticRegression-class or smth\n",
        "    The optimal logistic regression model\n",
        "  '''\n",
        "\n",
        "  # Calculate scores for all C's:\n",
        "  scores =\\\n",
        "    np.array( =\\\n",
        "      [ evaluate_performance_LR(X_train_std, y_train, X_CV_std, y_CV, C)\\\n",
        "       for C in Clist ]\\\n",
        "           )\n",
        "  # Determine the C that gives the maximum score on the cross-validation set.\n",
        "  ind_best = np.argmax(scores[:,1]) # for multiple max-values, it gives \n",
        "                                    # the first one, which is probably fine\n",
        "  C_best = Clist[ind_best]\n",
        "\n",
        "  # Define and train a logistic regression model with this best values of C.\n",
        "  LR_best = LogisticRegression(C = C_best)\n",
        "  LR_best.fit(X_train_std, y_train)\n",
        "\n",
        "  return scores, C_best, LR_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBIcngYOfYRm",
        "colab_type": "text"
      },
      "source": [
        "##### <font color = 'blue'> **Perform the comparison** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1amkAkAoLTXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d8e1fae4-0520-4c57-f957-81213ccf8cc0"
      },
      "source": [
        "# Compare different regularization parameters, and plot their performance\n",
        "Clist = [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000]\n",
        "scores, C_best, LR_best =\\\n",
        "  compare_regparams(X_train_std, y_train, X_CV_std, y_CV, C_list= C_list)\n",
        "\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.plot(Clist,scores[:,0],'bo')\n",
        "plt.plot(Clist,scores[:,1],'bs', color = 'orange')\n",
        "plt.xscale('log')\n",
        "plt.ylim((0,1.05))\n",
        "plt.xlabel('inverse regularization parameter C')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Performance as a fct of regularization parameter')\n",
        "plt.legend(('training accuracy', 'CV accuracy'), loc = 'lower right')\n",
        "\n",
        "#Summary of the best regularization parameter and the performance of the LR.\n",
        "## Determine scores\n",
        "score_train = logisticRegr.score(X_train_std, y_train)\n",
        "score_CV    = logisticRegr.score(X_CV_std   , y_CV)\n",
        "score_test  = logisticRegr.score(X_test_std , y_test)\n",
        "\n",
        "## Print summary\n",
        "msg = (f'Simple logistic regression was found to work best\\n'\n",
        "       f'with the inverse regularization parameter C = {C_best},\\n'\n",
        "       f'and gave the accuracies:\\n\\n'\n",
        "       f'score_train = {score_train:.2f},\\n'\n",
        "       f'score_CV    = {score_CV:.2f},\\n'\n",
        "       f'score_test  = {score_test:.2f}.' )\n",
        "\n",
        "print(msg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc3426b7a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}