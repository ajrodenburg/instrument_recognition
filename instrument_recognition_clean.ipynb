{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "instrument_recognition_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xjjSDBjiBLw8"
      ],
      "authorship_tag": "ABX9TyPcqbn6v0oVuL8G7d9mdeAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrodenburg/instrument_recognition/blob/Jeroen/instrument_recognition_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3LxhezCBjHi",
        "colab_type": "text"
      },
      "source": [
        "# <font color = #003399> **Instrument recognition** </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABKt-lmXBZTf",
        "colab_type": "text"
      },
      "source": [
        "## <font color = \"purple\"> **Initialize** </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_nIC2yLr7_D",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Import packages** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MixP7uByFt0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os       # For path-manipulations etc\n",
        "\n",
        "import librosa  # For all kinds of audio manipulations\n",
        "from librosa import display\n",
        "\n",
        "from IPython.display import Audio #to play audio inside the notebook\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7pQyQazsDgL",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Mount google drive** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCqcpjkvUNEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8e406d65-4c90-495a-d8eb-6600bb4448cc"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjjSDBjiBLw8",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"purple\"> **Import data** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofZpbKAue0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_data(data_dir, ins_annotations, max_songs_per_annotation = None):\n",
        "  \"\"\"\n",
        "  Imports the data.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data_dir : string\n",
        "    Path of the directory that contains the data. It is assumed that \n",
        "    this directory contains subdirectories, whose titles are given by\n",
        "    the annotations of the various instruments. The actual sound-files \n",
        "    are inside these subfolders.\n",
        "\n",
        "  ins_annotations : array of strings\n",
        "    List of the annotations of the various annotations - these strings \n",
        "    also the names of the subfolders that contain the data with that \n",
        "    annotation.\n",
        "\n",
        "  max_songs_per_annotations : int, optional\n",
        "    Maximum number of songs to include per annotation. Useful to test my code\n",
        "    while working only a smaller dataset.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  sampling_rates : np.array of ints\n",
        "    List of the sample-rates (in Hz) of all the music-files\n",
        "\n",
        "  data : list of np.arrays\n",
        "    List of time-domain data (in np.array format) of all music snippets.\n",
        "\n",
        "  classifications : np.array of strings\n",
        "    List of the annotation for every song - the annotation is for\n",
        "    the predominant instrument.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initalize the to-be-returned np.arrays\n",
        "  sampling_rates = [] #note: I'm choosing this to be a list, not a np.arrary.\n",
        "                    #The reaons is not very good -  but it seems easier to \n",
        "                    # append integers to a list. \n",
        "                    # If I were to intiialize sampling_rates as a np.array, \n",
        "                    # every entry of sampling_rates is automatically treated\n",
        "                    # as float64..\n",
        "  data = [] # note: its type is list, not np.array, because the data-signals \n",
        "            # it contains may - in principle - be of different length\n",
        "  classifications = np.array([])\n",
        "\n",
        "  # Import:\n",
        "  for annotation in ins_annotations:\n",
        "\n",
        "    print(f\"\\nImporting data with annotation '{annotation}'\")\n",
        "    data_subdir = os.path.join(data_dir,annotation)\n",
        "    list_filenames = os.listdir(data_subdir)\n",
        "\n",
        "    # Initialize counter that counts how many files are imported with this\n",
        "    # annotation --  used only to print this number during the importing.\n",
        "    counter = 0\n",
        "\n",
        "    for filename in list_filenames[:max_songs_per_annotation]:\n",
        "\n",
        "      dt, sr = librosa.load( os.path.join(data_subdir,filename), sr = None, mono = False )\n",
        "\n",
        "      data.append(dt)\n",
        "      sampling_rates.append( int(sr) )\n",
        "      classifications = np.append(classifications,annotation)\n",
        "\n",
        "      # print the number of imported snippets so far:\n",
        "      counter = counter + 1\n",
        "      print(f\"\\rImported snippets: {counter} of {len(list_filenames)}\", end = '')\n",
        "\n",
        "  return sampling_rates, data, classifications"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX_7JByJA5Eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "b993813d-6190-4380-ea01-b79e4998bc51"
      },
      "source": [
        "# Set working directory for this project\n",
        "base_dir = '/content/drive/My Drive/Colab Notebooks/instrument_recognition'\n",
        "os.chdir(base_dir)\n",
        "\n",
        "# Data directory:\n",
        "data_dir = os.path.join(base_dir,'data','IRMAS','trainingdata')\n",
        "# List of the strings used as instrument annotations\n",
        "ins_annotations = ['cel','cla','flu','gac','gel','org','pia','sax','tru','vio','voi']\n",
        "\n",
        "#Import data\n",
        "sampling_rates, data, y =\\\n",
        "  import_data(data_dir, ins_annotations, max_songs_per_annotation = None)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Importing data with annotation 'cel'\n",
            "Imported snippets: 5 of 388\n",
            "Importing data with annotation 'cla'\n",
            "Imported snippets: 5 of 505\n",
            "Importing data with annotation 'flu'\n",
            "Imported snippets: 5 of 451\n",
            "Importing data with annotation 'gac'\n",
            "Imported snippets: 5 of 637\n",
            "Importing data with annotation 'gel'\n",
            "Imported snippets: 5 of 760\n",
            "Importing data with annotation 'org'\n",
            "Imported snippets: 5 of 682\n",
            "Importing data with annotation 'pia'\n",
            "Imported snippets: 5 of 721\n",
            "Importing data with annotation 'sax'\n",
            "Imported snippets: 5 of 626\n",
            "Importing data with annotation 'tru'\n",
            "Imported snippets: 5 of 577\n",
            "Importing data with annotation 'vio'\n",
            "Imported snippets: 5 of 580\n",
            "Importing data with annotation 'voi'\n",
            "Imported snippets: 5 of 779"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJnlhtlC9kI",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"purple\"> **Preprocessing** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlPBSFADYbHJ",
        "colab_type": "text"
      },
      "source": [
        "**Features**: The first *n_mfcc* mel-frequency cepstral coefficients, time-averaged over all time-windows. *n_mfcc* can be specified.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y_qlA0pV2nh",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Supporting functions** </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrf49MsWVWAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain_average_mfccs(data, sampling_rates, window_time, time_step = None, n_mfcc = 20):\n",
        "  \"\"\"\n",
        "  Obtains, for every time-profile in 'data', the MFCC's (averaged over all time-windows) \n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data : list of m np.arrays of shape 2 x something\n",
        "    Here m is the number of snippets. Every entry of data contains the time-series of a single music snippet, \n",
        "    which is assumed to be stereo.\n",
        "\n",
        "  sampling_rates : list of m ints\n",
        "    Every int is the sample rate of the corresponding entry in data.\n",
        "\n",
        "  window_time : float\n",
        "    Length in seconds of a window to be used in the short-time Fourier transform,\n",
        "    that is part of the mfcc-routine.\n",
        "\n",
        "  time_step : float, optional\n",
        "    Length in seconds of the time step between two successive windows.\n",
        "    If not provided, it is set to window_time/2.\n",
        "\n",
        "  n_mfcc : int\n",
        "    Number of to-be-returned mel-frequency cepstral coefficients per snippet.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  average_mfccs : np.array of shape m x 2 x n_mfcc\n",
        "    Every entry of this list corresponds to one entry of data, and contains \n",
        "    the mfcc's averaged of the left- and right-component of the stereo signal.\n",
        "  \"\"\"\n",
        "\n",
        "  # If time_step is not defined, give it a standard value:\n",
        "  if time_step == None:\n",
        "    time_step = window_time / 2\n",
        "    print(f'The time-step is not specifed and therefore set to the standard value: window_time/2 = {time_step}')\n",
        "\n",
        "  # Define useful variable:\n",
        "  m = len(data)\n",
        "\n",
        "  # Initialize the to-be-returned np.array of average mfccs\n",
        "  average_mfccs = np.zeros((m,2,n_mfcc))\n",
        "\n",
        "  # Loop over data samples (snippets), \n",
        "  # and calculate the average mfcc's for every sample\n",
        "  for i in range(m):\n",
        "    # Parameters for dividing total time sample into windows:\n",
        "    ## Length of a window\n",
        "    n_fft = int(np.ceil(sampling_rates[i]*window_time)) \n",
        "    ## Hop length between two successive windows\n",
        "    hop_length = int(np.ceil(sampling_rates[i]*time_step))\n",
        "\n",
        "    # Calculate the mffc for the left- and right-audio\n",
        "    mfccs_left = librosa.feature.mfcc(data[i][0], sr = sampling_rates[i], n_fft = n_fft, hop_length = hop_length)\n",
        "    mfccs_right = librosa.feature.mfcc(data[i][1], sr = sampling_rates[i], n_fft = n_fft, hop_length = hop_length)\n",
        "\n",
        "    # Average mfccs over all time-windows,\n",
        "    # and store result in average_mfccs:\n",
        "    average_mfccs[i,0] = np.mean(mfccs_left,axis=1)\n",
        "    average_mfccs[i,1] = np.mean(mfccs_right,axis=1)\n",
        "\n",
        "    print(f'\\rNumber of average mfccs obtained: {i+1} out of {m}', end = '')\n",
        "\n",
        "  return average_mfccs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHF__E6VgCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardize(X, axis = None):\n",
        "  \"\"\"\n",
        "  `Standardizes' the elements of a 2D array: \n",
        "  To every entry we substract the mean of its column\n",
        "  and divide by the standard-deviation of its column.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X : np.array of shape (m,n) for ints m, n\n",
        "    To-be-standardized array\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  X_std : np.array of shape (m,n)\n",
        "    Standardized array\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute mean and standarddeviation for every column:\n",
        "  mu = np.mean(X, axis = 0)\n",
        "  sigma = np.std(X, axis = 0)\n",
        "\n",
        "  # For every element of array: \n",
        "  # substract mean and divide by standarddeviation\n",
        "  X_std = (X - mu)/sigma\n",
        "  ## Note that the shapes of array, mu and sigma do not match,\n",
        "  ## but the broadcasting property of the python operations '-'\n",
        "  ## and '/' ensures that it works as it should.\n",
        "\n",
        "  return X_std"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljpFr9KtELkY",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Perform the preprocessing** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T7oixwc5JAm",
        "colab_type": "text"
      },
      "source": [
        "**Remark on splitting of the data**: I'm using the IRMAS 'trainingdataset' as my **entire** dataset - which I will split into training, cross-validation and testingsets. This is the simplest thing to do right now. They also provide 'trainingdata', but it's of a different format than their trainingdata (longer snippets etc). It's interesting to test a trained classifier on that too - but a bit more complicated. For now, let's do the simplest thing possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMQ5XNpqE0UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_using_mfccs(data, sampling_rates, y,\\\n",
        "                           window_time, time_step = None, n_mfcc = 20,\\\n",
        "                           fraction_train = 0.6, fraction_test = 0.2):\n",
        "  '''\n",
        "  Takes the time-data, its sampling rates and its labels, and performs \n",
        "  the preprocessing: it returns the data and labels ready to be used for\n",
        "  machine learning algorithms. As features it uses, for every snippet, its\n",
        "  n_mfcc first time-averaged mfccs. It also separates the data into training, \n",
        "  cross-validation, and testdata. And it standardizes the features, i.e.\n",
        "  it makes sure that distribution of every coefficient has zero mean and unit\n",
        "  variance.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  data : list of m np.arrays of shape 2 x something\n",
        "    Here m is the number of snippets, and `something' the number of \n",
        "    time-samples of a single snippet. Every entry of data contains \n",
        "    the time-series of a single music snippet, which is assumed to be stereo.\n",
        "  \n",
        "  y : list of m strings.\n",
        "    y[i] is the annotation that corresponds to the snippet encoded by data[i].\n",
        "\n",
        "  sampling_rates : list of m ints\n",
        "    Every int is the sample rate of the corresponding entry in data.\n",
        "\n",
        "  window_time : float\n",
        "    Length in seconds of a window to be used in the short-time Fourier transform,\n",
        "    that is part of the mfcc-routine.\n",
        "\n",
        "  time_step : float, optional\n",
        "    Length in seconds of the time step between two successive windows.\n",
        "    If not provided, it is set to window_time/2.\n",
        "\n",
        "  n_mfcc : int, optional\n",
        "    Number of to-be-returned mel-frequency cepstral coefficients per snippet.\n",
        "    Standard value is 20.\n",
        "\n",
        "  fraction_train : float, s.t. 0 <= fraction_train <= 1.\n",
        "    Fraction of the total dataset to be used as trainingset.\n",
        "  \n",
        "  fraction_CV : float, s.t. 0 <= fraction_CV <= 1 - fraction_train.\n",
        "    Fraction of the total dataset to be used as trainingset.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train, n_mfcc)\n",
        "    Standardized training data. \n",
        "    Standardized means that every subset X_train[:,n_mfcc] was:\n",
        "      1. Shifted s.t. its mean = 0.\n",
        "      2. Normalized s.t. its standarddeviation = 1.\n",
        "  \n",
        "  X_CV_std : np.array of shape (m_CV, n_mfcc)\n",
        "    Standardized cross-validation data.\n",
        "\n",
        "  X_test_std : np.array of shape (m_test, n_mfcc)\n",
        "    Standardized testdata.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training data.\n",
        "\n",
        "  y_CV : np. array of shape (m_CV,)\n",
        "    Labels of cross-validation data.\n",
        "\n",
        "  y_test : np.array of shape (m_test,)\n",
        "    Labels of testdata.\n",
        "  '''\n",
        "\n",
        "  # Steps:\n",
        "  # (1) Obtain the time-averaged mfccs of every sample.\n",
        "  # (2) Reshape the resulting list of our stereo-data into more suitable format.\n",
        "  # (3) Split into training, cross-validation and testset.\n",
        "  # (4) Standardize features.\n",
        "\n",
        "  # Useful variable:\n",
        "  m = len(data)\n",
        "\n",
        "  # Step (1): Obtain the time-averaged mfccs of every sample.\n",
        "  average_mfccs = obtain_average_mfccs(data, sampling_rates, window_time = 0.030)\n",
        "\n",
        "  # Step (2): Reshape the resulting list of our stereo-data into more suitable format.\n",
        "  X = np.reshape(average_mfccs,(m,2*n_mfcc))\n",
        "\n",
        "  # Step (3): Split into training, cross-validation and testset.\n",
        "  ## Before splitting, we shuffle X & y:\n",
        "  from sklearn.utils import shuffle\n",
        "  X_shuffled, y_shuffled = shuffle(X,y)\n",
        "\n",
        "  ## Now, we split:\n",
        "\n",
        "  ### Define the fractions of the data to be used\n",
        "  ### for training, and cross-validation (CV); \n",
        "  ### the remainder will be the testing fraction:\n",
        "\n",
        "  fraction_train = 0.6\n",
        "  fraction_CV    = 0.2\n",
        "\n",
        "  ### Number of samples for training, CV and testing:\n",
        "  m_train = int( np.ceil( fraction_train * m ) )\n",
        "  m_CV    = int( np.ceil( fraction_CV * m  ) )\n",
        "  m_test  = m - m_train - m_CV\n",
        "\n",
        "  ### Split\n",
        "\n",
        "  X_train = X_shuffled[:m_train]\n",
        "  X_CV    = X_shuffled[m_train:(m_train+m_CV)]\n",
        "  X_test  = X_shuffled[-m_test:]\n",
        "\n",
        "  y_train = y_shuffled[:m_train]\n",
        "  y_CV    = y_shuffled[m_train:(m_train+m_CV)]\n",
        "  y_test  = y_shuffled[-m_test:]\n",
        "\n",
        "  # Step (4): Standarddize all features.\n",
        "\n",
        "  X_train_std = standardize(X_train)\n",
        "  X_CV_std = standardize(X_CV)\n",
        "  X_test_std = standardize(X_test)\n",
        "\n",
        "  return X_train_std, X_CV_std, X_test_std, y_train, y_CV, y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puslXSr9M8lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "328134a3-dffa-4366-dbc5-3f73fe8160c5"
      },
      "source": [
        "X_train_std, X_CV_std, X_test_std, y_train, y_CV, y_test = \\\n",
        "  preprocess_using_mfccs(data, sampling_rates, y,\\\n",
        "                         window_time = 0.030, time_step = None, n_mfcc = 20,\\\n",
        "                         fraction_train = 0.6, fraction_test = 0.2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time-step is not specifed and therefore set to the standard value: window_time/2 = 0.015\n",
            "Number of average mfccs obtained: 55 out of 55"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9zgmgLCHB2",
        "colab_type": "text"
      },
      "source": [
        "## <font color = \"purple\"> **Machine-learning** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv_j3xDqP0Bx",
        "colab_type": "text"
      },
      "source": [
        "Let's try a few different classifiers with different algorithms, and compare them. Let's start as simple as possible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFHSe2OP-lY",
        "colab_type": "text"
      },
      "source": [
        "### <font color = \"green\"> **Simple logistic regression** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W4IdhZHRC37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1rQWuGhZGd3",
        "colab_type": "text"
      },
      "source": [
        "#### <font color = '#CC3300'> **Compare different regularization parameters** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r37Io2uzfABu",
        "colab_type": "text"
      },
      "source": [
        "##### <font color = 'blue'> **Supporting functions** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s0e5DpPyIVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_performance_LR(X_train_std, y_train, X_CV_std, y_CV, C):\n",
        "  '''\n",
        "  Trains a Logistic-Regression-Classifier on a trainingset, \n",
        "  and returns its accuracy on the trainingset, as well as on a separate set\n",
        "  (cross-validation or test-set)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train,n_train)\n",
        "    Training data of m_train training samples and n_train standardized features.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training set\n",
        "\n",
        "  X_CV_std : np.array of shape (m_CV,n_CV)\n",
        "    Cross-validation or testing data of m_CV training samples\n",
        "    and n_CV standardized features.\n",
        "\n",
        "  y_CV : np.array of shape (m_CV,)\n",
        "    Labels of cross-valdation or test set.\n",
        "\n",
        "  C : float64 \n",
        "    inverse regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  np.array([score_train,score_CV]), where:\n",
        "\n",
        "  score_train : float 64 (where 0 <= score_train <=1 )\n",
        "    Accuracy of the trained logistic-regression-model on the training set.\n",
        "\n",
        "  score_CV : float 64 (where 0 <= score_CV <=1 )\n",
        "    Accuracy of the trained logistic-regression-model \n",
        "    on the cross-validation/test set.\n",
        "  '''\n",
        "\n",
        "  # Initalize Logistic Regression model\n",
        "  logisticRegr = LogisticRegression(C = C, max_iter = 1000)\n",
        "\n",
        "  # Train it\n",
        "  logisticRegr.fit(X_train_std, y_train)\n",
        "\n",
        "  # Evaluate accuracies\n",
        "  score_train = logisticRegr.score(X_train_std, y_train)\n",
        "  score_CV    = logisticRegr.score(X_CV_std   , y_CV)\n",
        "\n",
        "  return np.array([score_train,score_CV])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FLTyiVMZX_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_regparams(X_train_std, y_train, X_CV_std, y_CV,\\\n",
        "                      C_list= np.array([0.001,0.003,0.01,0.03,0.1,0.3,\\\n",
        "                              1,3,10,30,100,300,1000])\\\n",
        "                      ):\n",
        "  '''\n",
        "  Evaluates the performance of the logistic regression classifier for several\n",
        "  (inverse) regularaization parameters 'C'. Selects the best one by finding \n",
        "  the maximum accuracy on the cross-validation set. Returns the scores for \n",
        "  every C, the optimal C, and the optimal classifier.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X_train_std : np.array of shape (m_train,n_train)\n",
        "    Training data of m_train training samples and n_train standardized features.\n",
        "\n",
        "  y_train : np.array of shape (m_train,)\n",
        "    Labels of training set\n",
        "\n",
        "  X_CV_std : np.array of shape (m_CV,n_CV)\n",
        "    Cross-validation or testing data of m_CV training samples\n",
        "    and n_CV standardized features.\n",
        "\n",
        "  y_CV : np.array of shape (m_CV,)\n",
        "    Labels of cross-valdation or test set.\n",
        "\n",
        "  C_list : np.array of float64's \n",
        "    inverse regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  np.array([score_train,score_CV]), where:\n",
        "\n",
        "    score_train : float 64 (where 0 <= score_train <=1 )\n",
        "      Accuracy of the trained logistic-regression-model on the training set.\n",
        "\n",
        "    score_CV : float 64 (where 0 <= score_CV <=1 )\n",
        "      Accuracy of the trained logistic-regression-model \n",
        "    on the cross-validation/test set.\n",
        "  \n",
        "  C_best : float64\n",
        "    Optimal value of C, meaning that value of 'C_list' for which the accuracy \n",
        "    on the cross-validation set is maximal.\n",
        "\n",
        "  LR_best : LogisticRegression-class or smth\n",
        "    The optimal logistic regression model\n",
        "  '''\n",
        "\n",
        "  # Calculate scores for all C's:\n",
        "  scores =\\\n",
        "    np.array( \\\n",
        "      [ evaluate_performance_LR(X_train_std, y_train, X_CV_std, y_CV, C)\\\n",
        "       for C in Clist ]\\\n",
        "           )\n",
        "  # Determine the C that gives the maximum score on the cross-validation set.\n",
        "  ind_best = np.argmax(scores[:,1]) # for multiple max-values, it gives \n",
        "                                    # the first one, which is probably fine\n",
        "  C_best = Clist[ind_best]\n",
        "\n",
        "  # Define and train a logistic regression model with this best values of C.\n",
        "  LR_best = LogisticRegression(C = C_best)\n",
        "  LR_best.fit(X_train_std, y_train)\n",
        "\n",
        "  return scores, C_best, LR_best"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBIcngYOfYRm",
        "colab_type": "text"
      },
      "source": [
        "##### <font color = 'blue'> **Perform the comparison** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1amkAkAoLTXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "ef474ae8-918d-423c-fb85-1bd629fe83f3"
      },
      "source": [
        "# Compare different regularization parameters, and plot their performance\n",
        "C_list = [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000]\n",
        "scores, C_best, LR_best =\\\n",
        "  compare_regparams(X_train_std, y_train, X_CV_std, y_CV, C_list= C_list)\n",
        "\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.plot(Clist,scores[:,0],'bo')\n",
        "plt.plot(Clist,scores[:,1],'bs', color = 'orange')\n",
        "plt.xscale('log')\n",
        "plt.ylim((0,1.05))\n",
        "plt.xlabel('inverse regularization parameter C')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Performance as a fct of regularization parameter')\n",
        "plt.legend(('training accuracy', 'CV accuracy'), loc = 'lower right')\n",
        "\n",
        "#Summary of the best regularization parameter and the performance of the LR.\n",
        "## Determine scores\n",
        "score_train = LR_best.score(X_train_std, y_train)\n",
        "score_CV    = LR_best.score(X_CV_std   , y_CV)\n",
        "score_test  = LR_best.score(X_test_std , y_test)\n",
        "\n",
        "## Print summary\n",
        "msg = (f'Simple logistic regression was found to work best\\n'\n",
        "       f'with the inverse regularization parameter C = {C_best},\\n'\n",
        "       f'and gave the accuracies:\\n\\n'\n",
        "       f'score_train = {score_train:.2f},\\n'\n",
        "       f'score_CV    = {score_CV:.2f},\\n'\n",
        "       f'score_test  = {score_test:.2f}.' )\n",
        "\n",
        "print(msg)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple logistic regression was found to work best\n",
            "with the inverse regularization parameter C = 0.03,\n",
            "and gave the accuracies:\n",
            "\n",
            "score_train = 0.97,\n",
            "score_CV    = 0.45,\n",
            "score_test  = 0.45.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}